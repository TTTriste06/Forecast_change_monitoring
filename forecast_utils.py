import pandas as pd
import streamlit as st
import re

def merge_forecast_columns(forecast_dfs: dict[str, pd.DataFrame]) -> pd.DataFrame:
    """
    åˆå¹¶å¤šä¸ªé¢„æµ‹æ–‡ä»¶ï¼ŒæŒ‰â€œå“åâ€æ¨ªå‘åˆå¹¶æ‰€æœ‰é¢„æµ‹åˆ—ã€‚
    è¿”å›å€¼ä¸ºï¼šåŒ…å«â€œå“åâ€åˆ— + å¤šä¸ªâ€œyyyy-mmçš„é¢„æµ‹ï¼ˆç”Ÿæˆå¹´æœˆï¼‰â€åˆ—
    """
    all_parts = []
    for file_name, df in forecast_dfs.items():
        try:
            forecast_parts = parse_forecast_columns(df, file_name)
            for subdf in forecast_parts.values():
                all_parts.append(subdf)
        except Exception as e:
            st.warning(f"âš  å¤„ç† {file_name} å¤±è´¥ï¼š{e}")

    # ç»Ÿä¸€åˆå¹¶
    if not all_parts:
        return pd.DataFrame(columns=["å“å"])
    merged = all_parts[0]
    for part in all_parts[1:]:
        merged = pd.merge(merged, part, on="å“å", how="outer")

    return merged.fillna(0)


def parse_forecast_columns(df: pd.DataFrame, file_name: str) -> dict[str, pd.Series]:
    """
    ä»é¢„æµ‹è¡¨ä¸­æå–â€œxæœˆé¢„æµ‹â€åˆ—ï¼Œå¹¶è½¬æ¢ä¸ºâ€œyyyy-mmçš„é¢„æµ‹ï¼ˆç”Ÿæˆå¹´æœˆï¼‰â€æ ¼å¼
    """
    # ä»æ–‡ä»¶åä¸­æå–ç”Ÿæˆæ—¥æœŸ
    match = re.search(r"(\d{8})", file_name)
    if not match:
        raise ValueError(f"æ–‡ä»¶åä¸­æœªæ‰¾åˆ° 8 ä½æ—¥æœŸï¼š{file_name}")
    gen_date = pd.to_datetime(match.group(1), format="%Y%m%d")
    gen_year = gen_date.year
    gen_month = gen_date.month
    gen_ym_str = gen_date.strftime("%Y-%m")

    forecast_cols = {}
    month_pattern = re.compile(r"^(\d{1,2})æœˆé¢„æµ‹$")

    for col in df.columns:
        if isinstance(col, str):
            match = month_pattern.match(col.strip())
            if match:
                month_num = int(match.group(1))
                # å†³å®šå¹´ä»½ï¼ˆè·¨å¹´åˆ¤æ–­ï¼‰
                if month_num >= gen_month:
                    year = gen_year
                else:
                    year = gen_year + 1
                ym_key = f"{year}-{str(month_num).zfill(2)}"
                new_col_name = f"{ym_key}çš„é¢„æµ‹ï¼ˆ{gen_ym_str}ï¼‰"
                forecast_cols[new_col_name] = df[[col, "å“å"]].rename(columns={col: new_col_name})

    return forecast_cols  # è¿”å›åˆ—å â†’ dataframe with å“å + å•åˆ—


def load_forecast_files(files: dict) -> dict[str, pd.DataFrame]:
    """
    å¯¹ä¸Šä¼ çš„å¤šä¸ªé¢„æµ‹ Excel æ–‡ä»¶æ‰§è¡Œä»¥ä¸‹æ“ä½œï¼š
    - æ‰¾åˆ°æ¯ä¸ªæ–‡ä»¶ä¸­æœ€é•¿çš„ sheet
    - è‡ªåŠ¨è¯†åˆ« header è¡Œï¼ˆå«â€œäº§å“å‹å·â€çš„é‚£ä¸€è¡Œï¼‰
    - å°†ç¬¬äºŒåˆ—ç»Ÿä¸€å‘½åä¸ºâ€œå“åâ€
    - ç”¨ st.write æ‰“å°æ¯ä¸ªæ–‡ä»¶è¯»å–ç»“æœ
    è¿”å›å€¼ï¼šdict[file_name -> cleaned DataFrame]
    """
    result = {}

    for uploaded_file in files:
        file_name = uploaded_file.name
        try:
            xls = pd.ExcelFile(uploaded_file)
            longest_sheet = max(xls.sheet_names, key=lambda name: pd.read_excel(xls, sheet_name=name).shape[0])
            df_raw = pd.read_excel(xls, sheet_name=longest_sheet, header=None)

            # è‡ªåŠ¨è¯†åˆ« header è¡Œï¼šåŒ…å«â€œäº§å“å‹å·â€çš„è¡Œ
            header_row_idx = df_raw[df_raw.apply(lambda row: row.astype(str).str.contains("äº§å“å‹å·").any(), axis=1)].index
            if header_row_idx.empty:
                st.warning(f"âš  æ–‡ä»¶ {file_name} ä¸­æœªæ‰¾åˆ°åŒ…å«â€œäº§å“å‹å·â€çš„è¡¨å¤´è¡Œï¼Œè·³è¿‡")
                continue

            header_row = header_row_idx[0]
            df = pd.read_excel(xls, sheet_name=longest_sheet, header=header_row)

            # ç»Ÿä¸€ç¬¬äºŒåˆ—ä¸ºâ€œå“åâ€
            if df.shape[1] >= 2:
                df.columns.values[1] = "å“å"

            st.write(f"ğŸ“„ è¯»å–æˆåŠŸï¼š{file_name}ï¼ˆä½¿ç”¨ sheetï¼š{longest_sheet}ï¼Œheader è¡Œï¼šç¬¬ {header_row+1} è¡Œï¼‰")
            st.dataframe(df)

            result[file_name] = df

        except Exception as e:
            st.error(f"âŒ æ— æ³•è¯»å–æ–‡ä»¶ {file_name}: {e}")

    return result
