import streamlit as st
import pandas as pd
import re
from datetime import datetime
from mapping_utils import (
    apply_all_name_replacements,
    replace_all_names_with_mapping,
    clean_mapping_headers,
    split_mapping_data,
)
from io import BytesIO

st.set_page_config("ğŸ“Š å¤šé¢„æµ‹æ•´åˆå·¥å…·", layout="wide")
st.title("ğŸ“Š å¤šé¢„æµ‹æ•´åˆä¸å“åæå–")

# ===== ä¸Šä¼ åŒº =====
forecast_files = st.file_uploader("ğŸ“ ä¸Šä¼ å¤šä¸ªé¢„æµ‹æ–‡ä»¶", type=["xlsx"], accept_multiple_files=True)
order_file = st.file_uploader("ğŸ“„ ä¸Šä¼ è®¢å•æ–‡ä»¶ï¼ˆå«â€œæ™¶åœ†å“åâ€ï¼‰", type=["xlsx"])
sales_file = st.file_uploader("ğŸ“„ ä¸Šä¼ å‡ºè´§æ–‡ä»¶ï¼ˆå«â€œå“åã€æ™¶åœ†ã€è§„æ ¼â€ï¼‰", type=["xlsx"])
mapping_file = st.file_uploader("ğŸ§­ ä¸Šä¼ æ–°æ—§æ–™å·æ˜ å°„è¡¨", type=["xlsx"])

# ===== é…ç½®å­—æ®µæ˜ å°„ï¼ˆç”¨äº apply_all_name_replacementsï¼‰ =====
FIELD_MAPPINGS = {
    "é¢„æµ‹": {"å“å": "å“å"},
    "è®¢å•": {"å“å": "æ™¶åœ†å“å"},
    "å‡ºè´§": {"å“å": "å“å"},
}

# ===== æŒ‰é’®è§¦å‘ä¸»æµç¨‹ =====
if st.button("ğŸš€ å¼€å§‹å¤„ç†") and forecast_files and order_file and sales_file and mapping_file:
    # 1ï¸âƒ£ è§£ææ–°æ—§æ–™å·æ˜ å°„
    mapping_raw = pd.read_excel(mapping_file)
    mapping_df = clean_mapping_headers(mapping_raw)
    mapping_semi, mapping_new, mapping_sub = split_mapping_data(mapping_df)

    current_year = datetime.now().year
    all_parts = []

    # 2ï¸âƒ£ å¤„ç†æ¯ä¸ªé¢„æµ‹æ–‡ä»¶
    for uploaded_file in forecast_files:
        filename = uploaded_file.name
        # è¯»å–æœ€é•¿ sheet
        xls = pd.ExcelFile(uploaded_file)
        sheet_lengths = {sheet: pd.read_excel(xls, sheet).shape[0] for sheet in xls.sheet_names}
        longest_sheet = max(sheet_lengths, key=sheet_lengths.get)
        df_forecast = pd.read_excel(xls, sheet_name=longest_sheet, header=None)

        # æ£€æµ‹ header è¡Œï¼šå‰ä¸‰è¡Œä¸­æœ‰â€œäº§å“å‹å·â€è€…ä¸º header
        header_row = None
        for i in range(3):
            if any("äº§å“å‹å·" in str(cell) for cell in df_forecast.iloc[i]):
                header_row = i
                break
        if header_row is None:
            for i in range(3):
                if any(re.search(r"\d{1,2}æœˆé¢„æµ‹", str(cell)) for cell in df_forecast.iloc[i]):
                    header_row = i
                    break

        if header_row is not None:
            df_forecast.columns = df_forecast.iloc[header_row]
            df_forecast = df_forecast.iloc[header_row + 1:].reset_index(drop=True)
        else:
            st.warning(f"âš ï¸ æ— æ³•è¯†åˆ«é¢„æµ‹æ–‡ä»¶ `{filename}` çš„ headerï¼Œå·²è·³è¿‡")
            continue

        df_forecast = df_forecast.rename(columns=lambda x: str(x).strip())
        if "å“å" not in df_forecast.columns:
            st.warning(f"âš ï¸ é¢„æµ‹æ–‡ä»¶ `{filename}` ç¼ºå°‘â€œå“åâ€åˆ—ï¼Œå·²è·³è¿‡")
            continue

        df_forecast = df_forecast[["å“å"]].copy()
        df_forecast["å“å"] = df_forecast["å“å"].astype(str).str.strip()

        # æ›¿æ¢æ–°æ—§æ–™å·
        df_forecast, _ = apply_all_name_replacements(
            df_forecast,
            mapping_new,
            mapping_sub,
            sheet_name="é¢„æµ‹",
            field_mappings=FIELD_MAPPINGS,
        )
        all_parts.append(df_forecast)

    # 3ï¸âƒ£ å¤„ç†è®¢å•
    df_order = pd.read_excel(order_file)
    df_order["æ™¶åœ†å“å"] = df_order["æ™¶åœ†å“å"].astype(str).str.strip()
    df_order, _ = apply_all_name_replacements(df_order, mapping_new, mapping_sub, "è®¢å•", FIELD_MAPPINGS)
    all_parts.append(df_order[["æ™¶åœ†å“å"]].rename(columns={"æ™¶åœ†å“å": "å“å"}))

    # 4ï¸âƒ£ å¤„ç†å‡ºè´§
    df_sales = pd.read_excel(sales_file)
    df_sales["å“å"] = df_sales["å“å"].astype(str).str.strip()
    df_sales, _ = apply_all_name_replacements(df_sales, mapping_new, mapping_sub, "å‡ºè´§", FIELD_MAPPINGS)
    all_parts.append(df_sales[["å“å"]])

    # 5ï¸âƒ£ åˆå¹¶å»é‡å“åå¹¶è¿›è¡Œå†æ¬¡ç»Ÿä¸€æ›¿æ¢
    combined_names = pd.concat(all_parts, ignore_index=True)
    all_names = combined_names["å“å"].dropna().drop_duplicates().reset_index(drop=True)
    replaced_names = replace_all_names_with_mapping(all_names, mapping_new, mapping_sub)

    # 6ï¸âƒ£ æ„é€ æ€»è¡¨ï¼šæ™¶åœ† + è§„æ ¼ + å“åï¼Œä¼˜å…ˆä» mapping è¡¨ä¸­å–
    mapping_dict = mapping_new.set_index("æ–°å“å")[["æ–°æ™¶åœ†", "æ–°è§„æ ¼"]].copy()
    mapping_dict.columns = ["æ™¶åœ†", "è§„æ ¼"]

    df_final = pd.DataFrame({"å“å": replaced_names})
    df_final = df_final.merge(mapping_dict, how="left", left_on="å“å", right_index=True)

    # ä»è®¢å•æˆ–å‡ºè´§ä¸­è¡¥å……ç¼ºå¤±è§„æ ¼/æ™¶åœ†
    missing_spec = df_final["è§„æ ¼"].isna()
    if missing_spec.any():
        alt_spec = (
            pd.concat([df_order.rename(columns={"æ™¶åœ†å“å": "å“å"}), df_sales], ignore_index=True)
            .dropna(subset=["å“å"])
            .drop_duplicates(subset=["å“å"])
            [["å“å", "è§„æ ¼", "æ™¶åœ†"]]
        )
        df_final = df_final.merge(alt_spec, on="å“å", how="left", suffixes=("", "_alt"))
        df_final["è§„æ ¼"] = df_final["è§„æ ¼"].fillna(df_final["è§„æ ¼_alt"])
        df_final["æ™¶åœ†"] = df_final["æ™¶åœ†"].fillna(df_final["æ™¶åœ†_alt"])
        df_final = df_final.drop(columns=["è§„æ ¼_alt", "æ™¶åœ†_alt"])

    df_final = df_final[["æ™¶åœ†", "è§„æ ¼", "å“å"]]

    st.success("âœ… æ€»å“åè¡¨ç”ŸæˆæˆåŠŸï¼")
    st.dataframe(df_final, use_container_width=True)

    csv = df_final.to_csv(index=False, encoding="utf-8-sig")
    st.download_button("ğŸ“¥ ä¸‹è½½ç»“æœ CSV", csv, file_name="æ€»å“ååˆ—è¡¨.csv")
